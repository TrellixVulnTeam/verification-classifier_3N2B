{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Imports and setup\n",
    "\n",
    "Import the different dependencies from installed standard modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy import linalg\n",
    "\n",
    "%matplotlib inline\n",
    "offline.init_notebook_mode()\n",
    "pd.options.display.float_format = '{:.6f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the ad-hoc created modules for this project. We use the jupyter magics %load_ext autoreload and %autoreload set to 2.\n",
    "Imported classes are located in the ../scripts folder of our volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../scripts/')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from video_asset_processor import video_asset_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Process one asset and a number of renditions for analysis\n",
    "\n",
    "In this notebook we are evaluating a single asset and comparing the behavior of different renditions made at different resolutions and bitrates (500kbps and 250kbps) and with a watermark (@500kbps).\n",
    "The video_asset_processor.process function returns a dictionary containing the time history of the defined metrics (in this case only pixel difference ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_asset = '../data/7/bexPQO9gkSw.mp4'\n",
    "renditions_list = ['../data/6/bexPQO9gkSw.mp4',\n",
    "                   '../data/7.1/bexPQO9gkSw.mp4',\n",
    "                   '../data/7.2/bexPQO9gkSw.mp4',\n",
    "                   '../data/7.3/bexPQO9gkSw.mp4'\n",
    "                  ]\n",
    "metrics_list = ['temporal_difference']\n",
    "asset_processor = video_asset_processor(original_asset, renditions_list, metrics_list)\n",
    "asset_processor.display = False\n",
    "asset_processor.compute_time_history = True\n",
    "asset_metrics_dict = asset_processor.process()\n",
    "renditions_list.append('original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearrange the obtained data and put it in a pandas DataFrame for easier handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_df = {k: pd.DataFrame(v) for k,v in asset_metrics_dict.items()}\n",
    "metrics_df = pd.concat(dict_of_df, axis=1).transpose().reset_index(inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Plot the results: single original asset\n",
    "\n",
    "We will be using plotly's excellent library to output the measured instantaneous difference between a frame and its subsequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = metrics_df[metrics_df['level_1']=='original']\n",
    "\n",
    "trace = go.Scatter(\n",
    "        x = data_df['level_0'],\n",
    "        y = data_df['temporal_difference'],\n",
    "        name = 'Original',\n",
    "        mode = 'lines'\n",
    "    )\n",
    "\n",
    "data = [trace]\n",
    "layout = {\"title\": \"Temporal Pixel Difference Ratio:\", \n",
    "      \"legend\":{\"x\": .6, \"y\":.95},\n",
    "      \"xaxis\": {\"title\": \"Frame\", }, \n",
    "      \"yaxis\": {\"title\": \"Temporal pixel difference ratio\"},\n",
    "      \"hovermode\":\"closest\"\n",
    "      }\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Plot the results: compare against the created renditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "\n",
    "for rendition in renditions_list:\n",
    "    \n",
    "    data_df = metrics_df[metrics_df['level_1']==rendition]\n",
    "\n",
    "    trace = go.Scatter(\n",
    "            x = data_df['level_0'],\n",
    "            y = data_df['temporal_difference'],\n",
    "            name = rendition,\n",
    "            mode = 'lines'\n",
    "        )\n",
    "\n",
    "    data.append(trace)\n",
    "    \n",
    "layout = {\"title\": \"Temporal Pixel Difference Ratio:\", \n",
    "          \"legend\":{\"x\": .6, \"y\":.95},\n",
    "          \"xaxis\": {\"title\": \"Frame\", }, \n",
    "          \"yaxis\": {\"title\": \"Temporal pixel difference ratio\"},\n",
    "          \"hovermode\":\"closest\"\n",
    "          }\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Compare renditions by measuring different distances between them\n",
    "We will treat the resulting time series of instant pixel differences as a vector that enables us to compare different renditions.\n",
    "In order to be able to compare their behaviors individually we need a single scalar to do it. This will be the Euclidean distance. Other methods for analyzing time series similarity exist, but it happens so that Euclidean distance does a good job in our case. More sophysticated methods like Dynamic Time Warping (DWT) are in order when the characteristics of the time series present delayed patterns, as they allow for many-to-one point comparisions. In our analysis, only point-to-point distances aremore efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Rearrange the time series dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renditions_df = pd.DataFrame()\n",
    "frames = []\n",
    "for rendition in renditions_list:\n",
    "\n",
    "    rendition_df = metrics_df[metrics_df['level_1']==rendition]['temporal_difference']\n",
    "\n",
    "    \n",
    "    rendition_df = rendition_df.reset_index(drop=True).transpose()\n",
    "    frames.append(rendition_df)\n",
    "\n",
    "    \n",
    "\n",
    "renditions_df = pd.concat(frames,axis=1)\n",
    "renditions_df.columns=renditions_list\n",
    "renditions_df = renditions_df.astype(float)\n",
    "display(renditions_df.head())\n",
    "display(renditions_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Compute the cosine distance and the euclidean distance of the raw time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covmx = renditions_df.T.cov()\n",
    "invcovmx = linalg.pinv(covmx)\n",
    "\n",
    "x_original = np.array(renditions_df['original'].values)\n",
    "distances = {}\n",
    "\n",
    "for rendition in renditions_list:\n",
    "    x = np.array(renditions_df[rendition].values)\n",
    "\n",
    "    euclidean = distance.euclidean(x_original, x)\n",
    "    cosine = distance.cosine(x_original,x)\n",
    "    mahalanobis = distance.mahalanobis(x_original, x, invcovmx)\n",
    "    \n",
    "    distances[rendition] = {'Euclidean': euclidean, 'Cosine': cosine, 'Mahalanobis': mahalanobis}\n",
    "distances_raw_df = pd.DataFrame.from_dict(distances,orient='index')\n",
    "display(distances_raw_df.sort_values(by=['Cosine']))\n",
    "display(distances_raw_df.sort_values(by=['Euclidean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the cosine distances and euclidean distance of the smoothed time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourierFilter(x):\n",
    "    n = x.size\n",
    "    n_harm = 50                     # number of harmonics in model\n",
    "    t = np.arange(0, n)\n",
    "    p = np.polyfit(t, x, 1)         # find linear trend in x\n",
    "    x_notrend = x - p[0] * t        # detrended x\n",
    "    x_freqdom = np.fft.fft(x_notrend)  # detrended x in frequency domain\n",
    "    f = np.fft.fftfreq(n)              # frequencies\n",
    "    indexes = list(range(n))\n",
    "    # sort indexes by frequency, lower -> higher\n",
    "    indexes.sort(key = lambda i: np.absolute(f[i]))\n",
    " \n",
    "    t = np.arange(0, n)\n",
    "    restored_sig = np.zeros(t.size)\n",
    "    for i in indexes[:1 + n_harm * 2]:\n",
    "        ampli = np.absolute(x_freqdom[i]) / n   # amplitude\n",
    "        phase = np.angle(x_freqdom[i])          # phase\n",
    "        restored_sig += ampli * np.cos(2 * np.pi * f[i] * t + phase)\n",
    "    return restored_sig + p[0] * t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for rendition in renditions_list:\n",
    "    x = np.array(renditions_df[rendition].values)\n",
    "    extrapolation = fourierFilter(x)\n",
    "\n",
    "    trace = go.Scatter(\n",
    "                x = np.arange(0, extrapolation.size),\n",
    "                y = extrapolation,\n",
    "                name = rendition,\n",
    "                mode = 'lines'\n",
    "            )\n",
    "\n",
    "    data.append(trace)\n",
    "\n",
    "layout = {\"title\": \"Temporal pixel difference ratio:\", \n",
    "          \"legend\":{\"x\": .8, \"y\":.95},\n",
    "          \"xaxis\": {\"title\": \"Frame\", }, \n",
    "          \"yaxis\": {\"title\": \"Temporal pixel difference ratio\"},\n",
    "          \"hovermode\":\"closest\"\n",
    "          }\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_original = np.array(renditions_df['original'].values)\n",
    "extrapolation_original = fourierFilter(x_original)\n",
    "distances = {}\n",
    "\n",
    "for rendition in renditions_list:\n",
    "    x = np.array(renditions_df[rendition].values)\n",
    "    extrapolation_rendition = fourierFilter(x)\n",
    "\n",
    "    euclidean = distance.euclidean(extrapolation_original, extrapolation_rendition)\n",
    "    cosine = distance.cosine(extrapolation_original,extrapolation_rendition)\n",
    "    mahalanobis = distance.mahalanobis(extrapolation_original, extrapolation_rendition, invcovmx)\n",
    "    \n",
    "    distances[rendition] = {'Euclidean': euclidean, 'Cosine': cosine, 'Mahalanobis': mahalanobis}\n",
    "    \n",
    "distances_df = pd.DataFrame.from_dict(distances,orient='index').astype(float)\n",
    "\n",
    "display(distances_df)\n",
    "display(distances_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df=(distances_df-distances_df.mean())/distances_df.std()\n",
    "display(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df=(distances_df-distances_df.min())/(distances_df.max()-distances_df.min())\n",
    "display(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df = (distances_raw_df-distances_raw_df.mean())/distances_raw_df.std()\n",
    "display(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df=(distances_raw_df-distances_raw_df.min())/(distances_raw_df.max()-distances_raw_df.min())\n",
    "display(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
