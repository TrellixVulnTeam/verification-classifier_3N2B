{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i '../scripts/video_asset_processor.py' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metric_log(path, metric):\n",
    "    if metric == 'vmaf':\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                if '= ' in line:\n",
    "                    return float(line.split('= ')[-1])\n",
    "    if metric == 'ms-ssim':\n",
    "        ms_ssim_df = pd.read_csv(path)\n",
    "        return(ms_ssim_df['ms-ssim'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_dict = {}\n",
    "originals_path = '../data/{}/'\n",
    "for original_asset in glob.iglob(originals_path.format(7) + '**', recursive=False):\n",
    "    if os.path.isfile(original_asset): # filter dirs\n",
    "        #try:\n",
    "            start_time = time.time()\n",
    "            renditions_list = []\n",
    "            \n",
    "            #renditions_list.append(original_asset)\n",
    "            for i in range(3,7):\n",
    "                rendition_folder = originals_path.format(i)\n",
    "                renditions_list.append(rendition_folder + os.path.basename(original_asset))\n",
    "            asset_processor = video_asset_processor(original_asset, renditions_list)\n",
    "            asset_processor.display = False\n",
    "            asset_processor.compute_time_history = True\n",
    "            asset_metrics_dict = asset_processor.process()\n",
    "\n",
    "            dict_of_df = {k: pd.DataFrame(v) for k,v in asset_metrics_dict.items()}\n",
    "            df = pd.concat(dict_of_df, axis=1).transpose()\n",
    "            metrics = ['temporal_difference']\n",
    "            grouped_df = df.groupby(['dimensions'] + metrics, as_index=False).count()\n",
    "            renditions_dict = {}\n",
    "            for rendition in df['dimensions'].unique():\n",
    "                rendition_dict = {}\n",
    "                for metric in metrics:\n",
    "                    rendition_dict[metric] = grouped_df[grouped_df['dimensions']==rendition][metric].mean()\n",
    "                renditions_dict[rendition] = rendition_dict\n",
    "            metrics_dict[original_asset] = renditions_dict   \n",
    "            \n",
    "            elapsed_time = time.time() - start_time \n",
    "            print('Elapsed time:', elapsed_time)\n",
    "        #except Exception as err:\n",
    "        #    print('Failed to process asset:', original_asset, err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract aggregated metrics values to a pandas DataFrame\n",
    "\n",
    "Once we have iterated through each and every asset of the dataset, it is time to drop the contents of the dictionary to a pandas DataFrame.\n",
    "But before, other metrics computed by means of external scripts need to be collected (namely VMAF and MS-SSIM). Checkout Readme.md to see how to extract those metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_df = {k: pd.DataFrame(v) for k,v in metrics_dict.items()}\n",
    "metrics_df = pd.concat(dict_of_df, axis=1).transpose().reset_index(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_path = '../output'\n",
    "real_path = os.path.realpath(metrics_path)\n",
    "extra_metrics = ['vmaf', 'ms-ssim']\n",
    "\n",
    "for index,row in metrics_df.iterrows():\n",
    "    for metric in extra_metrics:\n",
    "    \n",
    "        asset_name = row['level_0'].split('/')[-1].split('.')[0]\n",
    "        dimension = row['level_1'].split(':')[0]\n",
    "        \n",
    "        log_path = '{}/{}/{}/{}/{}_{}.log'.format(real_path, metric, dimension, asset_name, asset_name, dimension)\n",
    "        if os.path.isfile(log_path): # filter dirs\n",
    "            metric_value = read_metric_log(log_path, metric)\n",
    "            metrics_df.at[index, metric] = metric_value\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('../output/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
