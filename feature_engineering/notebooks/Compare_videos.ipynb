{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Imports, setup and configure\n",
    "### 1.1.- Imports\n",
    "Bring in the different dependencies from installed standard modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the ad-hoc created modules for this project. We use the jupyter magics %load_ext autoreload and %autoreload set to 2. Imported classes are located in the ../scripts folder of our volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../scripts/asset_processor/')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from video_asset_processor import VideoAssetProcessor\n",
    "\n",
    "# Configure pandas to display enough information\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.- Custom functions\n",
    "Add the necessary custom functions for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metric_log(path, metric):\n",
    "    if metric == 'vmaf':\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                if '= ' in line:\n",
    "                    return float(line.split('= ')[-1])\n",
    "    if metric == 'ms-ssim':\n",
    "        ms_ssim_df = pd.read_csv(path)\n",
    "        return(ms_ssim_df['ms-ssim'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.- Configure the inputs\n",
    "Setup the needed parameters to pass to the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate the list of metrics to extract\n",
    "# -hash_euclidean\n",
    "# -hash_cosine\n",
    "# -hash_hamming\n",
    "# -temporal_difference (this creates two output columns): \n",
    "#  -temporal_difference_euclidean \n",
    "#  -temporal_difference_cosine\n",
    "\n",
    "metrics_list = ['temporal_difference', 'temporal_canny', 'temporal_histogram_distance', 'temporal_cross_correlation', 'temporal_dct']\n",
    "\n",
    "renditions_folders = [\n",
    "'1080p',\n",
    "'1080p_watermark',\n",
    "'1080p_flip_vertical',\n",
    "'1080p_rotate_90_clockwise',\n",
    "'1080p_vignette',\n",
    "'1080p_black_and_white',\n",
    "'1080p_low_bitrate_4',\n",
    "'720p',\n",
    "'720p_vignette',\n",
    "'720p_black_and_white',\n",
    "'720p_low_bitrate_4',\n",
    "'720p_watermark',\n",
    "'720p_flip_vertical',\n",
    "'720p_rotate_90_clockwise',\n",
    "'480p',\n",
    "'480p_watermark',\n",
    "'480p_vignette',\n",
    "'480p_black_and_white',\n",
    "'480p_low_bitrate_4',\n",
    "'480p_flip_vertical',\n",
    "'480p_rotate_90_clockwise',\n",
    "'360p',\n",
    "'360p_watermark',\n",
    "'360p_vignette',\n",
    "'360p_black_and_white',\n",
    "'360p_low_bitrate_4',\n",
    "'360p_flip_vertical',\n",
    "'360p_rotate_90_clockwise',\n",
    "'240p',\n",
    "'240p_watermark',\n",
    "'240p_vignette',\n",
    "'240p_black_and_white',\n",
    "'240p_low_bitrate_4',\n",
    "'240p_flip_vertical',\n",
    "'240p_rotate_90_clockwise',\n",
    "'144p',\n",
    "'144p_watermark',\n",
    "'144p_vignette',\n",
    "'144p_black_and_white',\n",
    "'144p_low_bitrate_4',\n",
    "'144p_flip_vertical',\n",
    "'144p_rotate_90_clockwise',\n",
    "]\n",
    "originals_path = '../../data/{}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Iterate all assets in the data set and extract their metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "list = os.listdir(originals_path.format('1080p')) # dir is your directory path\n",
    "number_assets = len(list)\n",
    "print ('Number of assets: {}'.format(number_assets))\n",
    "count = 0\n",
    "\n",
    "for original_asset in glob.iglob(originals_path.format('1080p') + '**', recursive=False):\n",
    "    count += 1\n",
    "    if os.path.isfile(original_asset): # filter dirs\n",
    "        print('Processing asset {} of {}: {}'.format(count, number_assets, original_asset))\n",
    "        start_time = time.time()\n",
    "        renditions_list = []\n",
    "\n",
    "        for folder in renditions_folders:\n",
    "            rendition_folder = originals_path.format(folder)\n",
    "            renditions_list.append(rendition_folder + os.path.basename(original_asset))\n",
    "\n",
    "        asset_processor = VideoAssetProcessor(original_asset, renditions_list, metrics_list, False)\n",
    "\n",
    "        asset_metrics_df = asset_processor.process()\n",
    "        \n",
    "        metrics_df = pd.concat([metrics_df, asset_metrics_df], axis=0, sort=False).reset_index(inplace=False)\n",
    "        if 'level_0' in metrics_df.columns:\n",
    "            metrics_df = metrics_df.drop(['level_0'], axis=1)\n",
    "\n",
    "        metrics_df.to_csv('../output/metrics-tmp.csv')\n",
    "        \n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Elapsed time:', elapsed_time)\n",
    "        print('***************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Extract aggregated metrics values to a pandas DataFrame\n",
    "\n",
    "Once we have iterated through each and every asset of the dataset, it is time to drop the contents of the dictionary to a pandas DataFrame.\n",
    "But before, other metrics computed by means of external scripts need to be collected (namely VMAF and MS-SSIM). Checkout Readme.md to see how to extract those metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_path = '../data-analysis/output'\n",
    "real_path = os.path.realpath(metrics_path)\n",
    "extra_metrics = ['vmaf', 'ms-ssim']\n",
    "\n",
    "for index,row in metrics_df.iterrows():\n",
    "    for metric in extra_metrics:\n",
    "\n",
    "        asset_name = row['level_0'].split('/')[-1].split('.')[0]\n",
    "        attack = row['level_1'].split('/')[3]\n",
    "        dimension = attack.split('_')[0].replace('p','')\n",
    "        attack_name = attack.replace('{}p'.format(dimension), dimension)\n",
    "        log_path = '{}/{}/{}/{}/{}_{}.log'.format(metrics_path, metric, attack_name, asset_name, asset_name, dimension)\n",
    "\n",
    "        print('LEVEL 0', row['level_0'])\n",
    "        print('LEVEL 1:', row['level_1'])\n",
    "        print('ASSET NAME:', asset_name)\n",
    "        print('ATTACK:', attack)\n",
    "        print('DIMENSION', dimension)\n",
    "        print('ATTACK NAME', attack_name)\n",
    "        print('PATH:', log_path)\n",
    "        \n",
    "        if os.path.isfile(log_path): \n",
    "            print('ADDING:',log_path)\n",
    "            print('*****************************')\n",
    "            metric_value = read_metric_log(log_path, metric)\n",
    "            metrics_df.at[index, metric] = metric_value\n",
    "        else:\n",
    "            print('Path not found')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('../output/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
