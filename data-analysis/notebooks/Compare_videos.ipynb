{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Imports, setup and configure\n",
    "### 1.1.- Imports\n",
    "Bring in the different dependencies from installed standard modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the ad-hoc created modules for this project. We use the jupyter magics %load_ext autoreload and %autoreload set to 2. Imported classes are located in the ../scripts folder of our volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../scripts')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from video_asset_processor import video_asset_processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.- Custom functions\n",
    "Add the necessary custom functions for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metric_log(path, metric):\n",
    "    if metric == 'vmaf':\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                if '= ' in line:\n",
    "                    return float(line.split('= ')[-1])\n",
    "    if metric == 'ms-ssim':\n",
    "        ms_ssim_df = pd.read_csv(path)\n",
    "        return(ms_ssim_df['ms-ssim'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.- Configure the inputs\n",
    "Setup the needed parameters to pass to the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate the list of metrics to extract\n",
    "# -hash_euclidean\n",
    "# -hash_cosine\n",
    "# -hash_hamming\n",
    "# -temporal_difference (this creates two output columns): \n",
    "#  -temporal_difference_euclidean \n",
    "#  -temporal_difference_cosine\n",
    "\n",
    "metrics_list = ['temporal_difference', 'temporal_canny', 'histogram_distance']\n",
    "\n",
    "renditions_folders = [\n",
    "'1080p',\n",
    "'1080p_watermark',\n",
    "'1080p_flip_vertical',\n",
    "'1080p_rotate_90_clockwise',\n",
    "'720p',\n",
    "'720p_watermark',\n",
    "'720p_flip_vertical',\n",
    "'720p_rotate_90_clockwise',\n",
    "'480p',\n",
    "'480p_watermark',\n",
    "'480p_flip_vertical',\n",
    "'480p_rotate_90_clockwise',\n",
    "'360p',\n",
    "'360p_watermark',\n",
    "'360p_flip_vertical',\n",
    "'360p_rotate_90_clockwise',\n",
    "'240p',\n",
    "'240p_watermark',\n",
    "'240p_flip_vertical',\n",
    "'240p_rotate_90_clockwise',\n",
    "'144p',\n",
    "'144p_watermark',\n",
    "'144p_flip_vertical',\n",
    "'144p_rotate_90_clockwise',\n",
    "]\n",
    "originals_path = '../../data/{}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Iterate all assets in the data set and extract their metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_dict = {}\n",
    "list = os.listdir(originals_path.format('1080p')) # dir is your directory path\n",
    "number_assets = len(list)\n",
    "print ('Number of assets: {}'.format(number_assets))\n",
    "count = 0\n",
    "\n",
    "for original_asset in glob.iglob(originals_path.format('1080p') + '**', recursive=False):\n",
    "    count += 1\n",
    "    if os.path.isfile(original_asset): # filter dirs\n",
    "        print('Processing asset {} of {}: {}'.format(count, number_assets, original_asset))\n",
    "        start_time = time.time()\n",
    "        renditions_list = []\n",
    "\n",
    "        for folder in renditions_folders:\n",
    "            rendition_folder = originals_path.format(folder)\n",
    "            renditions_list.append(rendition_folder + os.path.basename(original_asset))\n",
    "\n",
    "        asset_processor = video_asset_processor(original_asset, renditions_list, metrics_list)\n",
    "        asset_metrics_dict = asset_processor.process()\n",
    "\n",
    "        dict_of_df = {k: pd.DataFrame(v) for k,v in asset_metrics_dict.items()}\n",
    "\n",
    "        metrics_df = pd.concat(dict_of_df, axis=1).transpose().reset_index(inplace=False)\n",
    "        metrics_df = metrics_df.rename(index=str, columns={\"level_1\": \"frame_num\", \"level_0\": \"path\"})\n",
    "        \n",
    "        renditions_dict = {}\n",
    "        for rendition in renditions_list:\n",
    "            rendition_dict = {}\n",
    "            for metric in metrics_list:\n",
    "\n",
    "                original_df = metrics_df[metrics_df['path']==original_asset][metric]\n",
    "                original_df = original_df.reset_index(drop=True).transpose().dropna().astype(float)\n",
    "\n",
    "                rendition_df = metrics_df[metrics_df['path']==rendition][metric]\n",
    "                rendition_df = rendition_df.reset_index(drop=True).transpose().dropna().astype(float)\n",
    "\n",
    "                if  'temporal' in metric:\n",
    "                    x_original = np.array(original_df[rendition_df.index].values)\n",
    "                    x_rendition = np.array(rendition_df.values)\n",
    "                    std = std = metrics_df[metrics_df['path']==rendition]['temporal_difference'].std()\n",
    "                    rendition_dict['{}-euclidean'.format(metric)] = distance.euclidean(x_original, x_rendition)\n",
    "                    rendition_dict['{}-cosine'.format(metric)] = distance.cosine(x_original, x_rendition)\n",
    "                    #rendition_dict['{}-series'.format(metric)] = x_rendition\n",
    "                else:\n",
    "                    rendition_dict[metric] = rendition_df.mean()\n",
    "                \n",
    "            renditions_dict[rendition] = rendition_dict\n",
    "\n",
    "        metrics_dict[original_asset] = renditions_dict   \n",
    "\n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('Elapsed time:', elapsed_time)\n",
    "        print('***************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Extract aggregated metrics values to a pandas DataFrame\n",
    "\n",
    "Once we have iterated through each and every asset of the dataset, it is time to drop the contents of the dictionary to a pandas DataFrame.\n",
    "But before, other metrics computed by means of external scripts need to be collected (namely VMAF and MS-SSIM). Checkout Readme.md to see how to extract those metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_df = {k: pd.DataFrame(v) for k,v in metrics_dict.items()}\n",
    "metrics_df = pd.concat(dict_of_df, axis=1).transpose().reset_index(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics_path = '/home/jovyan/work/data-analysis/output'\n",
    "real_path = os.path.realpath(metrics_path)\n",
    "extra_metrics = ['vmaf', 'ms-ssim']\n",
    "\n",
    "for index,row in metrics_df.iterrows():\n",
    "    for metric in extra_metrics:\n",
    "\n",
    "        asset_name = row['level_0'].split('/')[-1].split('.')[0]\n",
    "        attack = row['level_1'].split('/')[3]\n",
    "        dimension = attack.split('_')[0].replace('p','')\n",
    "        attack_name = attack.replace('{}p'.format(dimension), dimension)\n",
    "        log_path = '{}/{}/{}/{}/{}_{}.log'.format(metrics_path, metric, attack_name, asset_name, asset_name, dimension)\n",
    "\n",
    "        print('LEVEL 0', row['level_0'])\n",
    "        print('LEVEL 1:', row['level_1'])\n",
    "        print('ASSET NAME:', asset_name)\n",
    "        print('ATTACK:', attack)\n",
    "        print('DIMENSION', dimension)\n",
    "        print('ATTACK NAME', attack_name)\n",
    "        print('PATH:', log_path)\n",
    "        \n",
    "        if os.path.isfile(log_path): \n",
    "            print('ADDING:',log_path)\n",
    "            print('*****************************')\n",
    "            metric_value = read_metric_log(log_path, metric)\n",
    "            metrics_df.at[index, metric] = metric_value\n",
    "        else:\n",
    "            print('Path not found')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('../output/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
