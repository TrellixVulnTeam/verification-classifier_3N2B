{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "from plotly import tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy import linalg\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, LSTM, RepeatVector, TimeDistributed, Dense, Dropout, Input\n",
    "from keras.optimizers import Adam \n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import Sequential\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../machine_learning/cloud_functions/data-large.csv'\n",
    "data = pd.read_csv(path)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['temporal_canny-series',\n",
    "           'temporal_cross_correlation-series',\n",
    "           'temporal_dct-series',\n",
    "           'temporal_difference-series',\n",
    "           'temporal_histogram_distance-series',\n",
    "           'temporal_gaussian-series',\n",
    "           'dimension',\n",
    "           'attack',\n",
    "           'title']\n",
    "\n",
    "\n",
    "df = df[columns]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = []\n",
    "attack_ID = []\n",
    "length = 70\n",
    "\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    time_series = np.fromstring(row['temporal_gaussian-series'].replace('[', '').replace(']', ''), \n",
    "                                                dtype=np.float, sep=' ')[:length]\n",
    "    if len(time_series) < length:\n",
    "        time_series = np.append(time_series, np.zeros(length - len(time_series)))\n",
    "\n",
    "    series.append(time_series)\n",
    "    if row['attack'] in ['1080p', '720p', '480p', '360p', '240p', '144p']:\n",
    "        attack_ID.append(1)\n",
    "    else:\n",
    "        attack_ID.append(0)\n",
    "        \n",
    "df['series'] = series\n",
    "df['attack_ID'] = attack_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "df_0 = df[df['attack_ID'] == 0]\n",
    "df_1 = df[df['attack_ID'] == 1]\n",
    "\n",
    "df_train = df_1[:int(0.8*df_1.shape[0])]\n",
    "df_test = df_1[int(0.8*df_1.shape[0]):]\n",
    "df_attacks = df_0\n",
    "\n",
    "train = np.stack(df_train['series'].to_numpy())\n",
    "test = np.stack(df_test['series'].to_numpy())\n",
    "attacks = np.stack(df_attacks['series'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "del df, df_train, df_attacks, df_0, df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = np.copy(train)\n",
    "test_ = np.copy(test)\n",
    "attacks_ = np.copy(attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_ = scaler.fit_transform(train_.reshape((train.shape[0]*train.shape[1], 1))).reshape((train.shape[0], train.shape[1]))\n",
    "test_ = scaler.transform(test_.reshape((test_.shape[0]*test.shape[1], 1))).reshape((test.shape[0], test.shape[1]))\n",
    "attacks_ = scaler.transform(attacks_.reshape((attacks_.shape[0]*attacks.shape[1], 1))).reshape((attacks.shape[0], attacks.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification by thresholding the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = np.quantile(np.mean(train_, axis=1), 0.99)\n",
    "\n",
    "mse_train = np.mean(train_, axis=1)\n",
    "mse_test = np.mean(test_, axis=1)\n",
    "mse_attacks = np.mean(attacks_, axis=1)\n",
    "\n",
    "print('Thresholding the 99% quantile')\n",
    "print('Train TPR: {}'.format(1 - sum(np.array(mse_train) > th) / len(mse_train)))\n",
    "print('Test TPR: {}'.format(1 - sum(np.array(mse_test) > th) / len(mse_test)))\n",
    "print('TNR: {}'.format(1 - sum(np.array(mse_attacks) < th) / len(mse_attacks)))\n",
    "\n",
    "true_positives = sum(np.array(mse_test) < th)\n",
    "false_negatives = sum(np.array(mse_test) > th)\n",
    "false_positives = sum(np.array(mse_attacks) < th)\n",
    "true_negatives = sum(np.array(mse_attacks) > th)\n",
    "\n",
    "beta = 20\n",
    "precision = true_positives/(true_positives+false_positives)\n",
    "recall = true_positives/(true_positives+false_negatives)\n",
    "F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "print('F20: {}'.format(F20))\n",
    "\n",
    "print('\\n-------------------\\n')\n",
    "\n",
    "th = np.quantile(mse_test, 0.999)\n",
    "print('Thresholding the 99.9% quantile')\n",
    "print('Train TPR: {}'.format(1 - sum(np.array(mse_train) > th) / len(mse_train)))\n",
    "print('Test TPR: {}'.format(1 - sum(np.array(mse_test) > th) / len(mse_test)))\n",
    "print('TNR: {}'.format(1 - sum(np.array(mse_attacks) < th) / len(mse_attacks)))\n",
    "\n",
    "true_positives = sum(np.array(mse_test) < th)\n",
    "false_negatives = sum(np.array(mse_test) > th)\n",
    "false_positives = sum(np.array(mse_attacks) < th)\n",
    "true_negatives = sum(np.array(mse_attacks) > th)\n",
    "\n",
    "beta = 20\n",
    "precision = true_positives/(true_positives+false_positives)\n",
    "recall = true_positives/(true_positives+false_negatives)\n",
    "F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "print('F20: {}'.format(F20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractive_loss(y_pred, y_true, lam=0.00001):\n",
    "    mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "\n",
    "    W = K.variable(value=model.get_layer('encoded').get_weights()[0])  # N x N_hidden\n",
    "    W = K.transpose(W)  # N_hidden x N\n",
    "    h = model.get_layer('encoded').output\n",
    "    dh = h * (1 - h)  # N_batch x N_hidden, derivative of sigmoid function\n",
    "    contractive = lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "\n",
    "    return mse + contractive\n",
    "\n",
    "\n",
    "def plot_history(network_history, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.semilogy(network_history.history['loss'])\n",
    "    plt.semilogy(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def print_scores(mse_train, mse_test, mse_attacks):\n",
    "    th = np.quantile(np.mean(train_, axis=1), 0.99)\n",
    "\n",
    "    mse_train = np.mean(train_, axis=1)\n",
    "    mse_test = np.mean(test_, axis=1)\n",
    "    mse_attacks = np.mean(attacks_, axis=1)\n",
    "\n",
    "    print('Thresholding the 99% quantile')\n",
    "    print('Train TPR: {}'.format(1 - sum(np.array(mse_train) > th) / len(mse_train)))\n",
    "    print('Test TPR: {}'.format(1 - sum(np.array(mse_test) > th) / len(mse_test)))\n",
    "    print('TNR: {}'.format(1 - sum(np.array(mse_attacks) < th) / len(mse_attacks)))\n",
    "\n",
    "    true_positives = sum(np.array(mse_test) < th)\n",
    "    false_negatives = sum(np.array(mse_test) > th)\n",
    "    false_positives = sum(np.array(mse_attacks) < th)\n",
    "    true_negatives = sum(np.array(mse_attacks) > th)\n",
    "\n",
    "    beta = 20\n",
    "    precision = true_positives/(true_positives+false_positives)\n",
    "    recall = true_positives/(true_positives+false_negatives)\n",
    "    F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "    print('F20: {}'.format(F20))\n",
    "\n",
    "    print('\\n-------------------\\n')\n",
    "\n",
    "    th = np.quantile(mse_test, 0.999)\n",
    "    print('Thresholding the 99.9% quantile')\n",
    "    print('Train TPR: {}'.format(1 - sum(np.array(mse_train) > th) / len(mse_train)))\n",
    "    print('Test TPR: {}'.format(1 - sum(np.array(mse_test) > th) / len(mse_test)))\n",
    "    print('TNR: {}'.format(1 - sum(np.array(mse_attacks) < th) / len(mse_attacks)))\n",
    "\n",
    "    true_positives = sum(np.array(mse_test) < th)\n",
    "    false_negatives = sum(np.array(mse_test) > th)\n",
    "    false_positives = sum(np.array(mse_attacks) < th)\n",
    "    true_negatives = sum(np.array(mse_attacks) > th)\n",
    "\n",
    "    beta = 20\n",
    "    precision = true_positives/(true_positives+false_positives)\n",
    "    recall = true_positives/(true_positives+false_negatives)\n",
    "    F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "    print('F20: {}'.format(F20))\n",
    "    \n",
    "def print_series(train_, train_re, test_, test_re, attacks_, attacks_re):\n",
    "    \n",
    "    f, axs = plt.subplots(3,5,figsize=(20,15))\n",
    "\n",
    "    ims = np.random.randint(0,3000,5)\n",
    "\n",
    "    axs[0,0].plot(train_[ims[0]])\n",
    "    axs[0,0].plot(train_re[ims[0]])\n",
    "\n",
    "    axs[0,1].plot(train_[ims[1]])\n",
    "    axs[0,1].plot(train_re[ims[1]])\n",
    "\n",
    "    axs[0,2].plot(train_[ims[2]])\n",
    "    axs[0,2].plot(train_re[ims[2]])\n",
    "\n",
    "    axs[0,3].plot(train_[ims[3]])\n",
    "    axs[0,3].plot(train_re[ims[3]])\n",
    "\n",
    "    axs[0,4].plot(train_[ims[4]])\n",
    "    axs[0,4].plot(train_re[ims[4]])\n",
    "\n",
    "\n",
    "    axs[1,0].plot(test_[ims[0]])\n",
    "    axs[1,0].plot(test_re[ims[0]])\n",
    "\n",
    "    axs[1,1].plot(test_[ims[1]])\n",
    "    axs[1,1].plot(test_re[ims[1]])\n",
    "\n",
    "    axs[1,2].plot(test_[ims[2]])\n",
    "    axs[1,2].plot(test_re[ims[2]])\n",
    "\n",
    "    axs[1,3].plot(test_[ims[3]])\n",
    "    axs[1,3].plot(test_re[ims[3]])\n",
    "\n",
    "    axs[1,4].plot(test_[ims[4]])\n",
    "    axs[1,4].plot(test_re[ims[4]])\n",
    "\n",
    "\n",
    "    axs[2,0].plot(attacks_[ims[0]])\n",
    "    axs[2,0].plot(attacks_re[ims[0]])\n",
    "\n",
    "    axs[2,1].plot(attacks_[ims[1]])\n",
    "    axs[2,1].plot(attacks_re[ims[1]])\n",
    "\n",
    "    axs[2,2].plot(attacks_[ims[2]])\n",
    "    axs[2,2].plot(attacks_re[ims[2]])\n",
    "\n",
    "    axs[2,3].plot(attacks_[ims[3]])\n",
    "    axs[2,3].plot(attacks_re[ims[3]])\n",
    "\n",
    "    axs[2,4].plot(attacks_[ims[4]])\n",
    "    axs[2,4].plot(attacks_re[ims[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = train_.shape[1]\n",
    "latent_dim = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(8 * latent_dim, activation='relu', input_shape=(n_in,)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(latent_dim, activation='linear', name='encoded'))\n",
    "model.add(Dense(8 * latent_dim, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(n_in, activation='tanh'))\n",
    "adam = Adam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='mae')\n",
    "model.summary()\n",
    "history = model.fit(train_, train_, epochs=450, verbose=0, \n",
    "                    batch_size=128, validation_data=(test_, test_), shuffle=True)\n",
    "\n",
    "plot_history(history, 'AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_re = model.predict(train_, batch_size=2048)\n",
    "test_re = model.predict(test_, batch_size=2048)\n",
    "attacks_re = model.predict(attacks_, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = [mean_squared_error(train_[i], train_re[i]) for i,_ in enumerate(train_)]\n",
    "mse_test = [mean_squared_error(test_[i], test_re[i]) for i, _ in enumerate(test_)]\n",
    "mse_attacks = [mean_squared_error(attacks_[i], attacks_re[i]) for i, _ in enumerate(attacks_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mse_train), np.mean(mse_test), np.mean(mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(mse_train), np.std(mse_test), np.std(mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(mse_train, mse_test, mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_series(train_, train_re, test_, test_re, attacks_, attacks_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study latent space and classify with OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = K.function([model.layers[0].input], [model.get_layer('encoded').output],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_red = encoder([train_])[0]\n",
    "test_red = encoder([test_])[0]\n",
    "attacks_red = encoder([attacks_])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "train_red_ = ss.fit_transform(train_red)\n",
    "test_red_ = ss.transform(test_red)\n",
    "attacks_red_ = ss.transform(attacks_red)\n",
    "\n",
    "variances = []\n",
    "components = reversed(range(1,train_red_.shape[1]+1))\n",
    "for i in components:\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(train_red_)\n",
    "    variances.append(sum(pca.explained_variance_ratio_))\n",
    "    \n",
    "trace = go.Scatter(\n",
    "x = list(reversed(range(1,test_red_.shape[1]+1))),\n",
    "y = variances)\n",
    "\n",
    "data=[trace]\n",
    "\n",
    "layout = {'title': 'PCA', \n",
    "      'xaxis': {'title': 'Number of components', }, \n",
    "      'yaxis': {'title': 'Variance explained'},\n",
    "      }\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(train_red)\n",
    "test_reduced = pca.transform(test_red)\n",
    "attack_reduced = pca.transform(attacks_red)\n",
    "\n",
    "f, ax = plt.subplots(1,3, figsize=(25,10))\n",
    "ax[0].set_title(\"Train set\")\n",
    "ax[1].set_title(\"Test set\")\n",
    "ax[2].set_title(\"Attack set\")\n",
    "ax[0].scatter(X_reduced[:,0], X_reduced[:,1], color='black')\n",
    "ax[1].scatter(test_reduced[:,0], test_reduced[:,1], color='red')\n",
    "ax[2].scatter(attack_reduced[:,0], attack_reduced[:,1], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(attack_reduced[:,0], attack_reduced[:,1], color='red', label='attack')\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], color='green', label='Train')\n",
    "plt.scatter(test_reduced[:,0], test_reduced[:,1], color='yellow', label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCSVM = svm.OneClassSVM(kernel='rbf',gamma='auto', nu=0.001, cache_size=7000, tol=0.00001, shrinking=False)\n",
    "OCSVM.fit(train_red)\n",
    "\n",
    "true_positives = sum(OCSVM.predict(test_red) == 1)\n",
    "false_negatives = sum(OCSVM.predict(test_red) == -1)\n",
    "false_positives = sum(OCSVM.predict(attacks_red) == 1)\n",
    "true_negatives = sum(OCSVM.predict(attacks_red) == -1)\n",
    "\n",
    "beta = 20\n",
    "precision = true_positives/(true_positives+false_positives)\n",
    "recall = true_positives/(true_positives+false_negatives)\n",
    "F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "print('F20: {}'.format(F20))\n",
    "print('Test TPR: {}'.format(true_positives/len(test_red)))\n",
    "print('TNR: {}'.format(true_negatives/len(attacks_red)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify by latent space uniqueness\n",
    "ids = np.unique(np.argmax(train_red, axis=1))\n",
    "ids, np.unique(np.argmax(test_red, axis=1)), np.unique(np.argmax(attacks_red, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = [1 if i in ids else 0 for i in np.argmax(test_red, axis=1)]\n",
    "attack_pred = [1 if i in ids else 0 for i in np.argmax(attacks_red, axis=1)]\n",
    "\n",
    "true_positives = sum(np.asarray(test_pred) == 1)\n",
    "false_negatives = sum(np.asarray(test_pred) == 0)\n",
    "false_positives = sum(np.asarray(attack_pred) == 1)\n",
    "true_negatives = sum(np.asarray(attack_pred) == 0)\n",
    "\n",
    "beta = 20\n",
    "precision = true_positives/(true_positives+false_positives)\n",
    "recall = true_positives/(true_positives+false_negatives)\n",
    "F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "print('F20: {}'.format(F20))\n",
    "print('Test TPR: {}'.format(true_positives/len(test_red)))\n",
    "print('TNR: {}'.format(true_negatives/len(attacks_red)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Input Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../machine_learning/cloud_functions/data-large.csv'\n",
    "data = pd.read_csv(path)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['temporal_canny-series',\n",
    "           'temporal_cross_correlation-series',\n",
    "           'temporal_dct-series',\n",
    "           'temporal_difference-series',\n",
    "           'temporal_histogram_distance-series',\n",
    "           'temporal_gaussian-series',\n",
    "           'dimension',\n",
    "           'attack',\n",
    "           'title']\n",
    "\n",
    "\n",
    "df = df[columns]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = []\n",
    "series_1 = []\n",
    "attack_ID = []\n",
    "length = 70\n",
    "\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    time_series = row['dimension']*np.fromstring(row['temporal_dct-series'].replace('[', '').replace(']', ''), \n",
    "                                                dtype=np.float, sep=' ')[:length]\n",
    "    time_series_1 = np.fromstring(row['temporal_gaussian-series'].replace('[', '').replace(']', ''), \n",
    "                                            dtype=np.float, sep=' ')[:length]\n",
    "    if len(time_series) < length:\n",
    "        time_series = np.append(time_series, np.zeros(length - len(time_series)))\n",
    "        \n",
    "    if len(time_series_1) < length: \n",
    "        time_series_1 = np.append(time_series_1, np.zeros(length - len(time_series_1)))\n",
    "        \n",
    "    series.append(time_series)\n",
    "    series_1.append(time_series_1)\n",
    "    if row['attack'] in ['1080p', '720p', '480p', '360p', '240p', '144p']:\n",
    "        attack_ID.append(1)\n",
    "    else:\n",
    "        attack_ID.append(0)\n",
    "        \n",
    "df['series'] = series\n",
    "df['series_1'] = series_1\n",
    "df['attack_ID'] = attack_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "df_0 = df[df['attack_ID'] == 0]\n",
    "df_1 = df[df['attack_ID'] == 1]\n",
    "\n",
    "df_train = df_1[:int(0.8*df_1.shape[0])]\n",
    "df_test = df_1[int(0.8*df_1.shape[0]):]\n",
    "df_attacks = df_0\n",
    "\n",
    "train = np.stack(df_train['series'].to_numpy())\n",
    "test = np.stack(df_test['series'].to_numpy())\n",
    "attacks = np.stack(df_attacks['series'].to_numpy())\n",
    "\n",
    "train_1 = np.stack(df_train['series_1'].to_numpy())\n",
    "test_1 = np.stack(df_test['series_1'].to_numpy())\n",
    "attacks_1 = np.stack(df_attacks['series_1'].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "del df, df_train, df_attacks, df_0, df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = np.copy(train)\n",
    "test_ = np.copy(test)\n",
    "attacks_ = np.copy(attacks)\n",
    "\n",
    "train_1 = np.copy(train_1)\n",
    "test_1 = np.copy(test_1)\n",
    "attacks_1 = np.copy(attacks_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "\n",
    "train_ = scaler.fit_transform(train_.reshape((train.size, 1))).reshape((train.shape[0],\n",
    "                                                                        train.shape[1]))\n",
    "test_ = scaler.transform(test_.reshape((test.size, 1))).reshape((test.shape[0],\n",
    "                                                                 test.shape[1]))\n",
    "attacks_ = scaler.transform(attacks_.reshape((attacks.size, 1))).reshape((attacks.shape[0],\n",
    "                                                                          attacks.shape[1]))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "\n",
    "train_1_ = scaler.fit_transform(train_1.reshape((train.size, 1))).reshape((train.shape[0],\n",
    "                                                                        train.shape[1]))\n",
    "test_1_ = scaler.transform(test_1.reshape((test.size, 1))).reshape((test.shape[0],\n",
    "                                                                 test.shape[1]))\n",
    "attacks_1_ = scaler.transform(attacks_1.reshape((attacks.size, 1))).reshape((attacks.shape[0],\n",
    "                                                                          attacks.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.hstack((train_, train_1_))\n",
    "test = np.hstack((test_, test_1_))\n",
    "attacks = np.hstack((attacks_, attacks_1_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train__ = train_ + np.random.normal(scale=0.005, size=(train_.shape[0], train_.shape[1]))\n",
    "test__ = test_ + np.random.normal(scale=0.005, size=(test_.shape[0], test_.shape[1]))\n",
    "attacks__ = attacks_ + np.random.normal(scale=0.005, size=(attacks_.shape[0], attacks_.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = train_.shape[1]\n",
    "latent_dim = 30\n",
    "model = Sequential()\n",
    "model.add(Dense(8 * latent_dim, activation='relu', input_shape=(n_in,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(latent_dim, activation='linear', name='encoded'))\n",
    "model.add(Dense(8 * latent_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_in, activation='linear'))\n",
    "adam = Adam(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='mae')\n",
    "model.summary()\n",
    "history = model.fit(train__, train_, epochs=150, verbose=0, \n",
    "                    batch_size=128, validation_data=(test__, test_), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, 'AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_re = model.predict(train__, batch_size=2048)\n",
    "test_re = model.predict(test__, batch_size=2048)\n",
    "attacks_re = model.predict(attacks__, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = [mean_squared_error(train_[i], train_re[i]) for i,_ in enumerate(train_)]\n",
    "mse_test = [mean_squared_error(test_[i], test_re[i]) for i, _ in enumerate(test_)]\n",
    "mse_attacks = [mean_squared_error(attacks_[i], attacks_re[i]) for i, _ in enumerate(attacks_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mse_train), np.mean(mse_test), np.mean(mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(mse_train), np.std(mse_test), np.std(mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(mse_train, mse_test, mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_series(train_, train_re, test_, test_re, attacks_, attacks_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study latent space and classify with OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = K.function([model.layers[0].input], [model.get_layer('encoded').output],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_red = encoder([train_])[0]\n",
    "test_red = encoder([test_])[0]\n",
    "attacks_red = encoder([attacks_])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "train_red_ = ss.fit_transform(train_red)\n",
    "test_red_ = ss.transform(test_red)\n",
    "attacks_red_ = ss.transform(attacks_red)\n",
    "\n",
    "variances = []\n",
    "components = reversed(range(1,train_red_.shape[1]+1))\n",
    "for i in components:\n",
    "    pca = PCA(n_components=i)\n",
    "    pca.fit(train_red_)\n",
    "    variances.append(sum(pca.explained_variance_ratio_))\n",
    "    \n",
    "trace = go.Scatter(\n",
    "x = list(reversed(range(1,test_red_.shape[1]+1))),\n",
    "y = variances)\n",
    "\n",
    "data=[trace]\n",
    "\n",
    "layout = {'title': 'PCA', \n",
    "      'xaxis': {'title': 'Number of components', }, \n",
    "      'yaxis': {'title': 'Variance explained'},\n",
    "      }\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(train_red)\n",
    "test_reduced = pca.transform(test_red)\n",
    "attack_reduced = pca.transform(attacks_red)\n",
    "\n",
    "f, ax = plt.subplots(1,3, figsize=(25,10))\n",
    "ax[0].set_title(\"Train set\")\n",
    "ax[1].set_title(\"Test set\")\n",
    "ax[2].set_title(\"Attack set\")\n",
    "ax[0].scatter(X_reduced[:,0], X_reduced[:,1], color='black')\n",
    "ax[1].scatter(test_reduced[:,0], test_reduced[:,1], color='red')\n",
    "ax[2].scatter(attack_reduced[:,0], attack_reduced[:,1], color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(attack_reduced[:,0], attack_reduced[:,1], color='red', label='attack')\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], color='green', label='Train')\n",
    "plt.scatter(test_reduced[:,0], test_reduced[:,1], color='yellow', label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCSVM = svm.OneClassSVM(kernel='rbf',gamma='auto', nu=0.001, cache_size=7000, tol=0.00001, shrinking=False)\n",
    "OCSVM.fit(train_red)\n",
    "\n",
    "true_positives = sum(OCSVM.predict(test_red) == 1)\n",
    "false_negatives = sum(OCSVM.predict(test_red) == -1)\n",
    "false_positives = sum(OCSVM.predict(attacks_red) == 1)\n",
    "true_negatives = sum(OCSVM.predict(attacks_red) == -1)\n",
    "\n",
    "beta = 20\n",
    "precision = true_positives/(true_positives+false_positives)\n",
    "recall = true_positives/(true_positives+false_negatives)\n",
    "F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "print('F20: {}'.format(F20))\n",
    "print('Test TPR: {}'.format(true_positives/len(test_red)))\n",
    "print('TNR: {}'.format(true_negatives/len(attacks_red)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify by latent space uniqueness\n",
    "ids = np.unique(np.argmax(train_red, axis=1))\n",
    "ids, np.unique(np.argmax(test_red, axis=1)), np.unique(np.argmax(attacks_red, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = [1 if i in ids else 0 for i in np.argmax(test_red, axis=1)]\n",
    "attack_pred = [1 if i in ids else 0 for i in np.argmax(attacks_red, axis=1)]\n",
    "\n",
    "true_positives = sum(np.asarray(test_pred) == 1)\n",
    "false_negatives = sum(np.asarray(test_pred) == 0)\n",
    "false_positives = sum(np.asarray(attack_pred) == 1)\n",
    "true_negatives = sum(np.asarray(attack_pred) == 0)\n",
    "\n",
    "beta = 20\n",
    "precision = true_positives/(true_positives+false_positives)\n",
    "recall = true_positives/(true_positives+false_negatives)\n",
    "F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "print('F20: {}'.format(F20))\n",
    "print('Test TPR: {}'.format(true_positives/len(test_red)))\n",
    "print('TNR: {}'.format(true_negatives/len(attacks_red)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train_.reshape(train.shape[0], train.shape[1], 1)\n",
    "test_ = test_.reshape(test.shape[0], test.shape[1], 1)\n",
    "attacks_ = attacks_.reshape(attacks.shape[0], attacks.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', input_shape=(train.shape[1], 1), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(RepeatVector(train.shape[1]))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss='mae')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_, train_, epochs=150, verbose=1, \n",
    "                    batch_size=512, validation_data=(test_, test_), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, 'AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, 'AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_re = model.predict(train_, batch_size=2048)\n",
    "test_re = model.predict(test_, batch_size=2048)\n",
    "attacks_re = model.predict(attacks_, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train = [mean_squared_error(train_[i], train_re[i]) for i,_ in enumerate(train_)]\n",
    "mse_test = [mean_squared_error(test_[i], test_re[i]) for i, _ in enumerate(test_)]\n",
    "mse_attacks = [mean_squared_error(attacks_[i], attacks_re[i]) for i, _ in enumerate(attacks_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mse_train), np.mean(mse_test), np.mean(mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(mse_train), np.std(mse_test), np.std(mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(mse_train, mse_test, mse_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_series(train_, train_re, test_, test_re, attacks_, attacks_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
