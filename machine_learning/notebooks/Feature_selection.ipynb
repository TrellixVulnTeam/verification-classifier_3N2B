{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sys.path.insert(0, '../../scripts/modeling_toolbox/')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from metric_processor import MetricProcessor\n",
    "import evaluation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels =  ['dimension', \n",
    "            'size',\n",
    "            'fps',\n",
    "            'temporal_difference-euclidean', \n",
    "            #'temporal_difference-manhattan',\n",
    "            #'temporal_difference-max', \n",
    "            #'temporal_difference-mean',\n",
    "            #'temporal_difference-std', \n",
    "            'temporal_cross_correlation-euclidean', \n",
    "            #'temporal_cross_correlation-manhattan',\n",
    "            #'temporal_cross_correlation-max', \n",
    "            #'temporal_cross_correlation-mean',\n",
    "            #'temporal_cross_correlation-std',\n",
    "            'temporal_dct-euclidean', \n",
    "            #'temporal_dct-manhattan',\n",
    "            #'temporal_dct-max', \n",
    "            #'temporal_dct-mean',\n",
    "            #'temporal_dct-std',\n",
    "            'temporal_canny-euclidean', \n",
    "            #'temporal_canny-manhattan',\n",
    "            #'temporal_canny-max', \n",
    "            #'temporal_canny-mean',\n",
    "            #'temporal_canny-std',\n",
    "            'temporal_gaussian-euclidean', \n",
    "            #'temporal_gaussian-manhattan',\n",
    "            #'temporal_gaussian-max', \n",
    "            #'temporal_gaussian-mean',\n",
    "            #'temporal_gaussian-std',\n",
    "            'temporal_histogram_distance-euclidean',\n",
    "            #'temporal_histogram_distance-manhattan',\n",
    "            #'temporal_histogram_distance-max', \n",
    "            #'temporal_histogram_distance-mean',\n",
    "            #'temporal_histogram_distance-std'\n",
    "               ]\n",
    "\n",
    "\n",
    "path = '../../machine_learning/cloud_functions/data-large.csv'\n",
    "\n",
    "metric_processor = MetricProcessor(feat_labels,'UL', path, reduced=True)\n",
    "df = metric_processor.read_and_process_data()\n",
    "\n",
    "N=10000\n",
    "df = df[:N]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat_labels)\n",
    "# Create X from the features\n",
    "X = df[feat_labels].drop(['title', 'attack', 'attack_ID'], axis=1).values\n",
    "\n",
    "# Create y from output\n",
    "y = df['attack_ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the features\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the target data\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 40% test and 60% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feat_labels, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "sfm = SelectFromModel(clf, threshold=0.05)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame()\n",
    "\n",
    "features_df['importance'] = clf.feature_importances_\n",
    "features_df['feature_name'] = list(df[feat_labels].drop(['title', 'attack', 'attack_ID'], axis=1))\n",
    "\n",
    "features_df.sort_values(by=['importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# View The Accuracy Of Our Full Feature (reduced Features) Model\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (2 Features) Model\n",
    "accuracy_score(y_test, y_important_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
