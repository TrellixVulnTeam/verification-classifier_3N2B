{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, '../../scripts/modeling_toolbox/')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from metric_processor import MetricProcessor\n",
    "import evaluation\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../machine_learning/cloud_functions/data-large.csv.old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['temporal_canny-euclidean', 'temporal_cross_correlation-euclidean',\n",
    "            'temporal_difference-euclidean', 'temporal_histogram_distance-euclidean',\n",
    "            'temporal_dct-euclidean', 'size', 'dimension', 'temporal_gaussian-mean',\n",
    "            'temporal_dct-std', 'temporal_dct-manhattan', 'temporal_dct-mean', 'temporal_histogram_distance-mean',\n",
    "            'temporal_cross_correlation-mean', 'temporal_canny-mean', 'temporal_gaussian-euclidean']\n",
    "\n",
    "\n",
    "metric_processor = MetricProcessor(features,'UL', path)\n",
    "df = metric_processor.read_and_process_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (df_train, df_test, df_attacks) = metric_processor.split_test_and_train(df)\n",
    "\n",
    "print('Shape of train: {}'.format(df_train.shape))\n",
    "print('Shape of test: {}'.format(df_test.shape))\n",
    "print('Shape of attacks: {}'.format(df_attacks.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['temporal_dct-mean', 'temporal_histogram_distance-mean', 'temporal_gaussian-mean']\n",
    "resolutions = [144, 240, 360, 480, 720]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the quantile of 99%, fixing the TPR to this value.\n",
    "\n",
    "params = {}\n",
    "quantile = 0.99\n",
    "\n",
    "for metric in metrics:    \n",
    "    params[metric] = {}\n",
    "    for res in resolutions:\n",
    "        th = np.quantile(df_train[df_train['attack'] == str(res) + 'p'][metric].to_numpy(), quantile)\n",
    "        params[metric][res] = th\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We need to extrapolate the thresholds for 1080p\n",
    "\n",
    "ticks = ['144p', '240p', '360p', '480p', '720p', '1080p']\n",
    "fig, ax = plt.subplots(len(metrics),1, figsize=(10, 15)) \n",
    "resolutions_ = resolutions.copy()\n",
    "resolutions_.extend([1080])\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ths = []\n",
    "    for res in resolutions:\n",
    "        ths.append(params[metric][res])\n",
    "    fit = np.polyfit(resolutions, np.log10(ths),1)\n",
    "    fit_means = np.poly1d(fit)\n",
    "    y_pred = fit_means(resolutions_)\n",
    "    \n",
    "    ax[i].semilogy(resolutions, ths, '--*', resolutions_, 10 ** y_pred, '--k')\n",
    "    ax[i].set_xticks(resolutions_)\n",
    "    _ = ax[i].set_xticklabels(ticks, rotation='horizontal', fontsize=18)\n",
    "    \n",
    "    params[metric][1080] = 10 ** y_pred[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The parameters of the curve are: y = {}*x + ({}) ## (Logarithmic)'.format(fit_means[1], fit_means[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    results_train[metric] = {}\n",
    "    for res in resolutions_:\n",
    "        results_train[metric][res] = df_train[df_train['attack'] == str(res) + 'p'][metric].to_numpy() > params[metric][res]\n",
    "        \n",
    "results_test = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    results_test[metric] = {}\n",
    "    for res in resolutions_:\n",
    "        results_test[metric][res] = df_test[df_test['attack'] == str(res) + 'p'][metric].to_numpy() > params[metric][res]\n",
    "\n",
    "results_attacks = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    results_attacks[metric] = {}\n",
    "    for res in resolutions_:\n",
    "        results_attacks[metric][res] = df_attacks[df_attacks['attack'].str.contains(str(res) + 'p')][metric].to_numpy() > params[metric][res]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_train = 0\n",
    "tp_test = 0\n",
    "fn_test = 0\n",
    "tn_attacks = 0\n",
    "fp_attacks = 0\n",
    "\n",
    "metric = 'temporal_gaussian-mean'\n",
    "for res in resolutions_:\n",
    "    tp_train += sum(results_train[metric][res] < params[metric][res])\n",
    "    tp_test += sum(results_test[metric][res] < params[metric][res])\n",
    "    fn_test += sum(results_test[metric][res] > params[metric][res])\n",
    "    tn_attacks += sum(results_attacks[metric][res] > params[metric][res])\n",
    "    fp_attacks += sum(results_attacks[metric][res] < params[metric][res])\n",
    "    \n",
    "beta = 20\n",
    "precision = tp_test/(tp_test+fp_attacks)\n",
    "recall = tp_test/(tp_test+fn_test)\n",
    "F20 = (1 + (beta ** 2))*precision*recall/((beta ** 2)*precision + recall)\n",
    "    \n",
    "print('With the metric {} we have:'.format(metric))\n",
    "print('TPR train: {}'.format(tp_train / df_train.shape[0]))\n",
    "print('TPR test: {}'.format(tp_test / df_test.shape[0]))\n",
    "print('TNR: {}'.format(tn_attacks / df_attacks.shape[0]))\n",
    "print('F20: {}'.format(F20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks['pred'] = df_attacks.apply(lambda row: row[metric] < params[metric][row['dimension']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attacks[df_attacks['pred'] == True].groupby(['dimension', 'attack']).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
