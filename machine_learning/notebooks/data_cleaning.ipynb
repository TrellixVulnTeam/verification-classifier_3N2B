{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras.backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up features from dataset\n",
    "\n",
    "Data coming from the preprocessing stage may contain experimental columns and unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame from the output csv\n",
    "data = pd.read_csv('../../machine_learning/cloud_functions/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "display(df.head())\n",
    "# Rename columns 'level_0' and 'level_1'\n",
    "df['title'] = df['level_0']\n",
    "df['variation'] = df['level_1']\n",
    "\n",
    "# Define a series containing the name of the kind of rendition variation\n",
    "attack_series = []\n",
    "# Define a series containing the label\n",
    "attack_IDs = []\n",
    "# Define a series containing the dimensions of the asset\n",
    "dimensions_series = []\n",
    "\n",
    "# Define a series with the variations that are only scaled down versions of the original\n",
    "# at a bitrate defined by Youtube's metadata\n",
    "renditions = ['1080p', '720p', '480p', '360p', '240p', '144p']\n",
    "\n",
    "# Scan all the rows\n",
    "for index, row in df.iterrows():\n",
    "    variation = row['variation'].split('/')[-2]\n",
    "    dimension = int(variation.split('_')[0].replace('p',''))\n",
    "    dimensions_series.append(dimension)\n",
    "    attack_series.append(variation)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        cell_value = str(row[column])\n",
    "\n",
    "        if '[' in cell_value:\n",
    "            cell_value = cell_value.replace('[','').replace(']','').split('  ')\n",
    "            if len(cell_value) == 1:\n",
    "                df.set_value(index, column, float(cell_value[0]))\n",
    "            else:\n",
    "                print(pd.to_numeric(cell_value, downcast='float', errors='coerce'))\n",
    "                print(range(5))\n",
    "                histogram = np.histogram(pd.to_numeric(cell_value, downcast='float', errors='coerce'), bins=[1,2,3,4,5])\n",
    "                df.set_value(index, column, histogram)\n",
    "            \n",
    "\n",
    "    # Every variation not belonging to the list of renditions is considered as an attack\n",
    "    # whose encodings were generated with good settings.\n",
    "    # Attacks (negative) are labeled as 0\n",
    "    # Non-attacks (positive) are labeled 1\n",
    "    if variation in renditions:\n",
    "            attack_IDs.append(1)\n",
    "    else:\n",
    "        attack_IDs.append(0)\n",
    "\n",
    "# Add the created series as columns of the dataframe\n",
    "df['attack'] = attack_series\n",
    "df['attack_ID'] = attack_IDs\n",
    "df['dimension'] = dimensions_series\n",
    "\n",
    "# Clean up \n",
    "df = df.drop(['Unnamed: 0',\n",
    "         'level_1'],axis=1)\n",
    "\n",
    "df =df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../data_analytics/output/metrics-clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
