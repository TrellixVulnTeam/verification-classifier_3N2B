{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies as setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc, fbeta_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import random_projection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "sys.path.insert(0, '../../scripts/modeling_toolbox/')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from metric_processor import MetricProcessor\n",
    "import evaluation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['temporal_canny-euclidean', 'temporal_cross_correlation-euclidean',\n",
    "            'temporal_difference-euclidean', 'temporal_histogram_distance-euclidean',\n",
    "            'temporal_dct-euclidean', 'size', 'dimension', 'fps',\n",
    "            'temporal_dct-std', 'temporal_dct-manhattan']\n",
    "\n",
    "\n",
    "path = '../../machine_learning/cloud_functions/data.csv'\n",
    "\n",
    "metric_processor = MetricProcessor(features,'SL', path)\n",
    "df = metric_processor.read_and_process_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_test_all, y_test_all), (x_train, y_train), (x_test, y_test) = metric_processor.split_test_and_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "MinMax_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled_MinMax = MinMax_scaler.fit_transform(x_train) \n",
    "X_test_scaled_MinMax = MinMax_scaler.transform(x_test) \n",
    "X_test_scaled_MinMax_all = MinMax_scaler.transform(x_test_all) \n",
    "\n",
    "Standard_scaler = StandardScaler()\n",
    "X_train_scaled_standard = Standard_scaler.fit_transform(x_train)\n",
    "X_test_scaled_standard = Standard_scaler.transform(x_test)\n",
    "X_test_scaled_standard_all = Standard_scaler.transform(x_test_all)\n",
    "\n",
    "# Save the scaler for inference\n",
    "pickle.dump(MinMax_scaler, open('../output/models/SL_MinMaxScaler.pickle.dat', 'wb'))\n",
    "pickle.dump(Standard_scaler, open('../output/models/SL_StandardScaler.pickle.dat', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = evaluation.neural_network(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nn_model.metrics_names)\n",
    "nn_model.evaluate(X_test_scaled_standard, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn_model.predict(X_test_scaled_standard)\n",
    "rounded = [round(x[0]) for x in y_pred]\n",
    "y_pred_bin = np.array(rounded, dtype='int64')\n",
    "confusion_matrix(y_test, y_pred_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(nn_model, X_test_scaled_standard, y_test, 'NN ROC', nn=True)\n",
    "fb = fbeta_score(y_test, y_pred_bin, beta=20, pos_label=1) \n",
    "print('TNR={}, TPR={}, F20={}'.format(1-fpr[1],tpr[1], fb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "# Save the weights\n",
    "NN_model.save_weights('../output/models/NN_model_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('../output/models/model_architecture.json', 'w') as f:\n",
    "    f.write(NN_model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_results = pd.DataFrame(columns=['n_components', 'TPR', 'TNR', 'model',\n",
    "                                              'auc', 'f_beta', 'projection', 'estimators'])\n",
    "random_forest_results = evaluation.random_forest(X_train_scaled_MinMax, y_train,\n",
    "                                      X_test_scaled_MinMax, y_test, random_forest_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_results.sort_values('f_beta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_random_forest = random_forest_results.sort_values('f_beta', ascending=False).iloc[0]\n",
    "projection = best_random_forest['projection']\n",
    "\n",
    "if projection == 'PCA':\n",
    "    reduction = PCA(n_components=best_random_forest['n_components'])\n",
    "    pickle.dump(reduction, open('../output/models/pca_random_forest.pickle.dat', 'wb'))\n",
    "\n",
    "elif projection == 'RP':\n",
    "    reduction = random_projection.SparseRandomProjection(n_components=best_random_forest['n_components'])\n",
    "    pickle.dump(reduction, open('../output/models/rp_random_forest.pickle.dat', 'wb'))\n",
    "else:\n",
    "    print('Unknown projection type')\n",
    "    \n",
    "X_reduced = reduction.fit_transform(X_train_scaled_MinMax)\n",
    "test_reduced = reduction.transform(X_test_scaled_MinMax)\n",
    "RF = RandomForestClassifier(n_estimators=int(best_random_forest['estimators']), n_jobs=7)\n",
    "\n",
    "RF.fit(X_reduced, y_train)\n",
    "\n",
    "pickle.dump(RF, open('../output/models/random_forest.pickle.dat', 'wb'))\n",
    "\n",
    "best_random_forest = best_random_forest.to_dict()\n",
    "best_random_forest['features'] = features\n",
    "with open('../output/models/random_forest_parameters.json', 'w') as fp:\n",
    "    json.dump(best_random_forest, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(RF, test_reduced, y_test, 'RF ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_results = pd.DataFrame(columns=['n_components', 'TPR', 'TNR', 'model',\n",
    "                                              'auc', 'f_beta', 'projection', 'LR'])\n",
    "ada_boost_results = evaluation.ada_boost(X_train_scaled_MinMax, y_train,\n",
    "                                      X_test_scaled_MinMax, y_test, ada_boost_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_results.sort_values('f_beta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_ada_boost_results = ada_boost_results.sort_values('f_beta', ascending=False).iloc[0]\n",
    "projection = best_ada_boost_results['projection']\n",
    "\n",
    "if projection == 'PCA':\n",
    "    reduction = PCA(n_components=best_ada_boost['n_components'])\n",
    "    pickle.dump(reduction, open('../output/models/pca_ada_boost.pickle.dat', 'wb'))\n",
    "\n",
    "elif projection == 'RP':\n",
    "    reduction = random_projection.SparseRandomProjection(n_components=best_ada_boost['n_components'])\n",
    "    pickle.dump(reduction, open('../output/models/rp_ada_boost.pickle.dat', 'wb'))\n",
    "else:\n",
    "    print('Unknown projection type')\n",
    "    \n",
    "X_reduced = reduction.fit_transform(X_train_scaled_MinMax)\n",
    "test_reduced = reduction.transform(X_test_scaled_MinMax)\n",
    "adaBoost  = AdaBoostClassifier(learning_rate=best_ada_boost['LR'])\n",
    "adaBoost.fit(X_reduced, y_train)\n",
    "\n",
    "pickle.dump(adaBoost, open('../output/models/AdaBoost.pickle.dat', 'wb'))\n",
    "\n",
    "best_ada_boost_results = best_ada_boost_results.to_dict()\n",
    "best_ada_boost_results['features'] = features\n",
    "with open('../output/models/adaBoost_parameters.json', 'w') as fp:\n",
    "    json.dump(best_ada_boost_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(adaBoost, test_reduced, y_test, 'AdaBoost ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results = pd.DataFrame(columns=['n_components', 'TPR', 'TNR', 'model',\n",
    "                                              'auc', 'f_beta', 'projection'])\n",
    "svm_results = evaluation.svm_classifier(X_train_scaled_MinMax, y_train,\n",
    "                                        X_test_scaled_MinMax, y_test, svm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results.sort_values('f_beta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_svm_results = svm_results.sort_values('f_beta', ascending=False).iloc[0]\n",
    "projection = best_svm_results['projection']\n",
    "\n",
    "if projection == 'PCA':\n",
    "    reduction = PCA(n_components=best_svm_results['n_components'])\n",
    "    pickle.dump(reduction, open('../output/models/pca_svm.pickle.dat', 'wb'))\n",
    "\n",
    "elif projection == 'RP':\n",
    "    reduction = random_projection.SparseRandomProjection(n_components=best_svm_results['n_components'])\n",
    "    pickle.dump(reduction, open('../output/models/rp_svm.pickle.dat', 'wb'))\n",
    "else:\n",
    "    print('Unknown projection type')\n",
    "    \n",
    "X_reduced = reduction.fit_transform(X_train_scaled_MinMax)\n",
    "test_reduced = reduction.transform(X_test_scaled_MinMax)\n",
    "svc  = svm.SVC(gamma='auto', cache_size=7000)\n",
    "svc.fit(X_reduced, y_train)\n",
    "\n",
    "pickle.dump(svc, open('../output/models/svm.pickle.dat', 'wb'))\n",
    "\n",
    "best_svm_results = best_svm_results.to_dict()\n",
    "best_svm_results['features'] = features\n",
    "with open('../output/models/svm_parameters.json', 'w') as fp:\n",
    "    json.dump(best_svm_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(svc, test_reduced, y_test, 'SVM ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_results = pd.DataFrame(columns=['n_components', 'TPR', 'TNR', 'model',\n",
    "                                              'auc', 'f_beta', 'projection'])\n",
    "xgboost_results = evaluation.xg_boost(X_train_scaled_MinMax, y_train,\n",
    "                                      X_test_scaled_MinMax, y_test, xgboost_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_results.sort_values('f_beta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled_MinMax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_xgboost_results = xgboost_results.sort_values('f_beta', ascending=False).iloc[0]\n",
    "projection = best_xgboost_results['projection']\n",
    "\n",
    "if projection == 'PCA':\n",
    "    reduction = PCA(n_components=best_xgboost_results['n_components'])\n",
    "    pickle.dump(reduction, open('../output/models/pca_svm.pickle.dat', 'wb'))\n",
    "\n",
    "elif projection == 'RP':\n",
    "    reduction = random_projection.SparseRandomProjection(n_components=best_xgboost_results['n_components'])\n",
    "    pickle.dump(reduction, open('../output/models/rp_svm.pickle.dat', 'wb'))\n",
    "else:\n",
    "    print('Unknown projection type')\n",
    "    \n",
    "X_reduced = reduction.fit_transform(X_train_scaled_MinMax)\n",
    "test_reduced = reduction.transform(X_test_scaled_MinMax)\n",
    "\n",
    "XGB = xgb.XGBClassifier()\n",
    "grid = {'max_depth':10}\n",
    "XGB.set_params(**grid)\n",
    "\n",
    "XGB.fit(X_reduced, y_train)\n",
    "\n",
    "pickle.dump(XGB, open('../output/models/XGBoost.pickle.dat', 'wb'))\n",
    "\n",
    "best_xgboost_results = best_xgboost_results.to_dict()\n",
    "best_xgboost_results['features'] = features\n",
    "with open('../output/models/xgboost_parameters.json', 'w') as fp:\n",
    "    json.dump(best_xgboost_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(XGB, test_reduced, y_test, 'XGB ROC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
