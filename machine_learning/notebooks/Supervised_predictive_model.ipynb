{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc, fbeta_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import random_projection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "sys.path.insert(0, '../../scripts/modeling_toolbox/')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from metric_processor import MetricProcessor\n",
    "import evaluation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['dimension', \n",
    "            'size',\n",
    "            'fps',\n",
    "            'temporal_difference-euclidean', \n",
    "            #'temporal_difference-manhattan',\n",
    "            #'temporal_difference-max', \n",
    "            #'temporal_difference-mean',\n",
    "            #'temporal_difference-std', \n",
    "            'temporal_dct-euclidean', \n",
    "            #'temporal_dct-manhattan',\n",
    "            #'temporal_dct-max', \n",
    "            #'temporal_dct-mean',\n",
    "            #'temporal_dct-std',\n",
    "            'temporal_gaussian-euclidean', \n",
    "            #'temporal_gaussian-manhattan',\n",
    "            #'temporal_gaussian-max', \n",
    "            #'temporal_gaussian-mean',\n",
    "            #'temporal_gaussian-std',\n",
    "            'temporal_histogram_distance-euclidean',\n",
    "            #'temporal_histogram_distance-manhattan',\n",
    "            #'temporal_histogram_distance-max', \n",
    "            #'temporal_histogram_distance-mean',\n",
    "            #'temporal_histogram_distance-std'\n",
    "               ]\n",
    "path = '../../machine_learning/cloud_functions/data-large.csv'\n",
    "\n",
    "metric_processor = MetricProcessor(features,'SL', path, reduced=False)\n",
    "df = metric_processor.read_and_process_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_test_all, y_test_all), (x_train, y_train), (x_test, y_test) = metric_processor.split_test_and_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "MinMax_scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled_MinMax = MinMax_scaler.fit_transform(x_train) \n",
    "X_test_scaled_MinMax = MinMax_scaler.transform(x_test) \n",
    "X_test_scaled_MinMax_all = MinMax_scaler.transform(x_test_all) \n",
    "\n",
    "Standard_scaler = StandardScaler()\n",
    "X_train_scaled_standard = Standard_scaler.fit_transform(x_train)\n",
    "X_test_scaled_standard = Standard_scaler.transform(x_test)\n",
    "X_test_scaled_standard_all = Standard_scaler.transform(x_test_all)\n",
    "\n",
    "# Save the scaler for inference\n",
    "pickle.dump(MinMax_scaler, open('../output/models/SL_MinMaxScaler.pickle.dat', 'wb'))\n",
    "pickle.dump(Standard_scaler, open('../output/models/SL_StandardScaler.pickle.dat', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_results = pd.DataFrame(columns=['n_components', 'TPR', 'TNR', 'model',\n",
    "                                              'auc', 'f_beta', 'projection', 'estimators'])\n",
    "random_forest_results = evaluation.random_forest(X_train_scaled_MinMax, y_train,\n",
    "                                      X_test_scaled_MinMax, y_test, random_forest_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_results.sort_values('f_beta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_random_forest = random_forest_results.sort_values('f_beta', ascending=False).iloc[0]\n",
    "projection = best_random_forest['projection']\n",
    "\n",
    "if projection == 'PCA':\n",
    "    reduction = PCA(n_components=best_random_forest['n_components'])\n",
    "elif projection == 'RP':\n",
    "    reduction = random_projection.SparseRandomProjection(n_components=best_random_forest['n_components'])\n",
    "else:\n",
    "    print('Unknown projection type')\n",
    "    \n",
    "X_reduced = reduction.fit_transform(X_train_scaled_MinMax)\n",
    "test_reduced = reduction.transform(X_test_scaled_MinMax)\n",
    "\n",
    "pickle.dump(reduction, open('../output/models/reduction_RF.pickle.dat', 'wb'))\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=int(best_random_forest['estimators']), n_jobs=7)\n",
    "\n",
    "RF.fit(X_reduced, y_train)\n",
    "\n",
    "pickle.dump(RF, open('../output/models/RF.pickle.dat', 'wb'))\n",
    "\n",
    "best_random_forest = best_random_forest.to_dict()\n",
    "best_random_forest['features'] = features\n",
    "with open('../output/models/param_RF.json', 'w') as fp:\n",
    "    json.dump(best_random_forest, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(RF, test_reduced, y_test, 'RF ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_results = pd.DataFrame(columns=['n_components', 'TPR', 'TNR', 'model',\n",
    "                                              'auc', 'f_beta', 'projection', 'LR'])\n",
    "ada_boost_results = evaluation.ada_boost(X_train_scaled_MinMax, y_train,\n",
    "                                      X_test_scaled_MinMax, y_test, ada_boost_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_results.sort_values('f_beta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_ada_boost_results = ada_boost_results.sort_values('f_beta', ascending=False).iloc[0]\n",
    "projection = best_ada_boost_results['projection']\n",
    "\n",
    "if projection == 'PCA':\n",
    "    reduction = PCA(n_components=best_ada_boost_results['n_components'])\n",
    "\n",
    "elif projection == 'RP':\n",
    "    reduction = random_projection.SparseRandomProjection(n_components=best_ada_boost_results['n_components'])\n",
    "else:\n",
    "    print('Unknown projection type')\n",
    "    \n",
    "X_reduced = reduction.fit_transform(X_train_scaled_MinMax)\n",
    "test_reduced = reduction.transform(X_test_scaled_MinMax)\n",
    "pickle.dump(reduction, open('../output/models/reduction_AdaBoost.pickle.dat', 'wb'))\n",
    "\n",
    "\n",
    "adaBoost  = AdaBoostClassifier(learning_rate=best_ada_boost_results['LR'])\n",
    "adaBoost.fit(X_reduced, y_train)\n",
    "\n",
    "pickle.dump(adaBoost, open('../output/models/AdaBoost.pickle.dat', 'wb'))\n",
    "\n",
    "best_ada_boost_results = best_ada_boost_results.to_dict()\n",
    "best_ada_boost_results['features'] = features\n",
    "with open('../output/models/param_AdaBoost.json', 'w') as fp:\n",
    "    json.dump(best_ada_boost_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(adaBoost, test_reduced, y_test, 'AdaBoost ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results = pd.DataFrame(columns=['n_components', 'TPR', 'TNR', 'model',\n",
    "                                              'auc', 'f_beta', 'projection'])\n",
    "svm_results = evaluation.svm_classifier(X_train_scaled_MinMax, y_train,\n",
    "                                        X_test_scaled_MinMax, y_test, svm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_results.sort_values('f_beta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_svm_results = svm_results.sort_values('f_beta', ascending=False).iloc[0]\n",
    "projection = best_svm_results['projection']\n",
    "\n",
    "if projection == 'PCA':\n",
    "    reduction = PCA(n_components=best_svm_results['n_components'])\n",
    "elif projection == 'RP':\n",
    "    reduction = random_projection.SparseRandomProjection(n_components=best_svm_results['n_components'])\n",
    "else:\n",
    "    print('Unknown projection type')\n",
    "    \n",
    "X_reduced = reduction.fit_transform(X_train_scaled_MinMax)\n",
    "test_reduced = reduction.transform(X_test_scaled_MinMax)\n",
    "\n",
    "pickle.dump(reduction, open('../output/models/reduction_SVM.pickle.dat', 'wb'))\n",
    "\n",
    "svc  = svm.SVC(gamma='auto', cache_size=7000)\n",
    "svc.fit(X_reduced, y_train)\n",
    "\n",
    "pickle.dump(svc, open('../output/models/SVM.pickle.dat', 'wb'))\n",
    "\n",
    "best_svm_results = best_svm_results.to_dict()\n",
    "best_svm_results['features'] = features\n",
    "with open('../output/models/param_SVM.json', 'w') as fp:\n",
    "    json.dump(best_svm_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(svc, test_reduced, y_test, 'SVM ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_results = pd.DataFrame(columns=['n_components', 'TPR', 'TNR', 'model',\n",
    "                                              'auc', 'f_beta', 'projection'])\n",
    "xgboost_results = evaluation.xg_boost(X_train_scaled_MinMax, y_train,\n",
    "                                      X_test_scaled_MinMax, y_test, xgboost_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_results.sort_values('f_beta', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_xgboost_results = xgboost_results.sort_values('f_beta', ascending=False).iloc[0]\n",
    "projection = best_xgboost_results['projection']\n",
    "\n",
    "if projection == 'PCA':\n",
    "    reduction = PCA(n_components=best_xgboost_results['n_components'])\n",
    "\n",
    "elif projection == 'RP':\n",
    "    reduction = random_projection.SparseRandomProjection(n_components=best_xgboost_results['n_components'])\n",
    "else:\n",
    "    print('Unknown projection type')\n",
    "    \n",
    "X_reduced = reduction.fit_transform(X_train_scaled_MinMax)\n",
    "test_reduced = reduction.transform(X_test_scaled_MinMax)\n",
    "pickle.dump(reduction, open('../output/models/reduction_XGBoost.pickle.dat', 'wb'))\n",
    "\n",
    "\n",
    "XGB = xgb.XGBClassifier()\n",
    "grid = {'max_depth':10}\n",
    "XGB.set_params(**grid)\n",
    "\n",
    "XGB.fit(X_reduced, y_train)\n",
    "\n",
    "pickle.dump(XGB, open('../output/models/XGBoost.pickle.dat', 'wb'))\n",
    "\n",
    "best_xgboost_results = best_xgboost_results.to_dict()\n",
    "best_xgboost_results['features'] = features\n",
    "with open('../output/models/param_XGBoost.json', 'w') as fp:\n",
    "    json.dump(best_xgboost_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.plot_roc_supervised(XGB, test_reduced, y_test, 'XGB ROC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
