{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import random_projection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import fbeta_score, roc_curve, auc\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "offline.init_notebook_mode(connected=False)\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "sys.path.insert(0, '../../scripts/modeling_toolbox/')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from metric_processor import MetricProcessor\n",
    "import evaluation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['dimension',\n",
    "            'size',\n",
    "            'temporal_dct-mean', \n",
    "            'temporal_gaussian_mse-mean', \n",
    "            'temporal_gaussian_difference-mean',\n",
    "            'temporal_threshold_gaussian_difference-mean',\n",
    "            #'temporal_match-mean'\n",
    "           ]\n",
    "\n",
    "\n",
    "path = '../../machine_learning/cloud_functions/data-large.csv'\n",
    "\n",
    "metric_processor = MetricProcessor(features,'UL', path, reduced=False, scale=True, bins=0)\n",
    "df = metric_processor.read_and_process_data(unique_ID=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We remove the low bitrates since we are only focused on tampering attacks. The rotation attacks are also\n",
    "# removed since they will be detected by the pre-verifier just by checking output dimensions\n",
    "#df = df[~(df['attack'].str.contains('low_bitrate')) & ~(df['attack'].str.contains('rotate'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, X_attacks), (df_train, df_test, df_attacks) = metric_processor.split_test_and_train(df.drop(['unique_ID'], axis=1))\n",
    "\n",
    "print('Shape of train: {}'.format(X_train.shape))\n",
    "print('Shape of test: {}'.format(X_test.shape))\n",
    "print('Shape of attacks: {}'.format(X_attacks.shape))\n",
    "\n",
    "print(X_train)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test are **only** composed by legit assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(X_train)\n",
    "x_test = ss.transform(X_test)\n",
    "x_attacks = ss.transform(X_attacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "OCSVM = svm.OneClassSVM(kernel='rbf',gamma='auto', nu=0.01, cache_size=5000)\n",
    "\n",
    "OCSVM.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb, area, tnr, tpr_train, tpr_test = evaluation.unsupervised_evaluation(OCSVM, x_train, x_test, x_attacks)\n",
    "# Show global results of classification\n",
    "print('TNR: {}\\nTPR_test: {}\\nTPR_train: {}\\n'.format(tnr, tpr_test, tpr_train))\n",
    "print('F20: {}\\nAUC: {}'.format(fb, area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show mean distances to the decision function. A negative distance means that the data is classified as\n",
    "# an attack\n",
    "df_train['dist_to_dec_funct'] = OCSVM.decision_function(x_train)\n",
    "df_test['dist_to_dec_funct'] = OCSVM.decision_function(x_test)\n",
    "df_attacks['dist_to_dec_funct'] = OCSVM.decision_function(x_attacks)\n",
    "display(df_train.describe())\n",
    "display(df_test.describe())\n",
    "display(df_attacks.describe())\n",
    "print('Mean score values:\\n-Train: {}\\n-Test: {}\\n-Attacks: {}'.format(df_train['dist_to_dec_funct'].mean(),\n",
    "                                                                       df_test['dist_to_dec_funct'].mean(),\n",
    "                                                                       df_attacks['dist_to_dec_funct'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QoE metrics-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../machine_learning/cloud_functions/data-qoe-large.csv'\n",
    "\n",
    "features_qoe = ['dimension',\n",
    "            'size',\n",
    "            'temporal_ssim-mean', \n",
    "            'temporal_psnr-mean',\n",
    "            'temporal_ssim-euclidean', \n",
    "            'temporal_psnr-euclidean'\n",
    "           ]\n",
    "\n",
    "metric_processor = MetricProcessor(features_qoe, 'UL', path, reduced=10000, bins=0, scale=False)\n",
    "df_qoe = metric_processor.read_and_process_data(unique_ID=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to merge QoE dataframe and add features from training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qoe = pd.merge(left=df, right=df_qoe, left_on='unique_ID', right_on='unique_ID')\n",
    "\n",
    "df_qoe = df_qoe.rename(columns={'attack_ID_x': 'attack_ID',\n",
    "                       'title_x': 'title',\n",
    "                       'attack_x': 'attack',\n",
    "                       'dimension_x': 'dimension',\n",
    "                       'size_x': 'size',\n",
    "                               })\n",
    "df_qoe = df_qoe.drop(['attack_ID_y', 'title_y', 'attack_y'], axis=1)\n",
    "\n",
    "df_qoe['color'] = df_qoe['attack_ID'].apply(lambda x: 'red' if x>=10 else 'green')\n",
    "\n",
    "# Convert PSNR to a linear value so we can establish a threshold\n",
    "max_error = np.log10(255*255)\n",
    "df_qoe['mse'] = df_qoe['temporal_psnr-mean'].apply(lambda x: 10**((10 * max_error - x)/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_qoe.shape)\n",
    "df_qoe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make the prediction using the simple QoE assumption establishing a threshold\n",
    "df_qoe['ssim_pred'] = df_qoe['temporal_ssim-mean'].apply(lambda x: 1 if x > 0.9 else -1)\n",
    "df_qoe['mse_pred'] = df_qoe['mse'].apply(lambda x: 1 if x < 15 else -1)\n",
    "df_qoe['psnr_pred'] = df_qoe['temporal_psnr-mean'].apply(lambda x: 1 if x > 35 else -1)\n",
    "\n",
    "\n",
    "# Make prediction using OCSVM\n",
    "x_ocsvm = ss.transform(df_qoe[features])\n",
    "\n",
    "df_qoe['ocsvm_pred'] = OCSVM.predict(x_ocsvm)\n",
    "df_qoe['ocsvm_dist'] = OCSVM.decision_function(x_ocsvm)\n",
    "display(df_qoe.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qoe_evaluation(prediction, train_set, test_set, attack_set, beta=20):\n",
    "\n",
    "    y_pred_train = train_set[prediction]\n",
    "    y_pred_test = test_set[prediction]\n",
    "    y_pred_outliers = attack_set[prediction]\n",
    "\n",
    "    n_accurate_train = y_pred_train[y_pred_train == 1].size\n",
    "    n_accurate_test = y_pred_test[y_pred_test == 1].size\n",
    "    n_accurate_outliers = y_pred_outliers[y_pred_outliers == -1].size\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(np.concatenate([np.ones(y_pred_test.shape[0]), -1*np.ones(y_pred_outliers.shape[0])]),\n",
    "                            np.concatenate([y_pred_test, y_pred_outliers]), pos_label=1)\n",
    "    fb = fbeta_score(np.concatenate([np.ones(y_pred_test.shape[0]), -1*np.ones(y_pred_outliers.shape[0])]),\n",
    "                     np.concatenate([y_pred_test, y_pred_outliers]), beta=beta, pos_label=1)\n",
    "\n",
    "    tnr = n_accurate_outliers/attack_set.shape[0]\n",
    "    tpr_test = n_accurate_test/test_set.shape[0]\n",
    "    tpr_train = n_accurate_train/train_set.shape[0]\n",
    "\n",
    "    area = auc(fpr, tpr)\n",
    "    return fb, area, tnr, tpr_train, tpr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the naive QoE assumption\n",
    "\n",
    "(X_train, X_test, X_attacks), (df_qoe_train, df_qoe_test, df_qoe_attacks) = metric_processor.split_test_and_train(df_qoe)\n",
    "\n",
    "print('Shape of train: {}'.format(X_train.shape))\n",
    "print('Shape of test: {}'.format(X_test.shape))\n",
    "print('Shape of attacks: {}'.format(X_attacks.shape))\n",
    "accuracy_df = pd.DataFrame(columns=['f20', 'area', 'tnr', 'tpr_train', 'tpr_test'])\n",
    "\n",
    "accuracy_df.loc['SSIM'] = qoe_evaluation('ssim_pred',\n",
    "                                         df_qoe_train,\n",
    "                                         df_qoe_test,\n",
    "                                         df_qoe_attacks)\n",
    "accuracy_df.loc['PSNR'] = qoe_evaluation('psnr_pred',\n",
    "                                         df_qoe_train,\n",
    "                                         df_qoe_test,\n",
    "                                         df_qoe_attacks)\n",
    "\n",
    "accuracy_df.loc['MSE'] = qoe_evaluation('mse_pred',\n",
    "                                         df_qoe_train,\n",
    "                                         df_qoe_test,\n",
    "                                         df_qoe_attacks)\n",
    "accuracy_df.loc['OCSVM'] = qoe_evaluation('ocsvm_pred',\n",
    "                                         df_qoe_train,\n",
    "                                         df_qoe_test,\n",
    "                                         df_qoe_attacks)\n",
    "\n",
    "display(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_features = features + ['temporal_psnr-mean', 'temporal_ssim-mean', 'mse']\n",
    "for feature in compare_features:\n",
    "    traceSources = go.Scatter(\n",
    "        x = df_qoe['ocsvm_dist'],\n",
    "        y =  df_qoe[feature],\n",
    "        #z =  df_qoe['dimension'],\n",
    "        hoverinfo='skip',\n",
    "        mode = 'markers',\n",
    "        text = df_qoe['attack'].values,\n",
    "        showlegend = False,\n",
    "         marker = dict(\n",
    "             size = 2,\n",
    "             color = df_qoe['color'], \n",
    "             showscale = False,\n",
    "             opacity = 0.8\n",
    "        )\n",
    "    )\n",
    "    data = [traceSources]\n",
    "\n",
    "    layout = dict(title = 'OCSVM decision function vs {}'.format(feature),\n",
    "\n",
    "                  hovermode= 'closest',\n",
    "                  yaxis = dict(zeroline=False, title=feature),\n",
    "                  xaxis = dict(zeroline=False, title='Decision function'),\n",
    "                  showlegend= True,\n",
    "                 height=900\n",
    "                 )\n",
    "\n",
    "    fig = dict(data=data,\n",
    "               layout=layout\n",
    "               )\n",
    "\n",
    "    offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
