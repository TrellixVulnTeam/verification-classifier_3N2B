{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import random_projection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import fbeta_score, roc_curve, auc\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as offline\n",
    "from plotly import tools\n",
    "\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "sys.path.insert(0, '../../scripts/modeling_toolbox/')\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "%autoreload 2\n",
    "\n",
    "from metric_processor import MetricProcessor\n",
    "import evaluation\n",
    "\n",
    "%matplotlib inline\n",
    "offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['temporal_dct-mean', 'temporal_gaussian-mean', 'temporal_spatial_complexity-mean',\n",
    "           'temporal_difference-mean', 'dimension', 'temporal_gaussian_difference-mean']\n",
    "\n",
    "path = '../../machine_learning/cloud_functions/data-large.csv'\n",
    "\n",
    "metric_processor = MetricProcessor(features,'UL', path)\n",
    "df = metric_processor.read_and_process_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, X_attacks), (df_train, df_test, df_attacks) = metric_processor.split_test_and_train(df)\n",
    "\n",
    "print('Shape of train: {}'.format(X_train.shape))\n",
    "print('Shape of test: {}'.format(X_test.shape))\n",
    "print('Shape of attacks: {}'.format(X_attacks.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(X_train)\n",
    "x_test = ss.transform(X_test)\n",
    "x_attacks = ss.transform(X_attacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCSVM = svm.OneClassSVM(kernel='rbf',gamma='auto', nu=0.01, cache_size=5000)\n",
    "OCSVM.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb, area, tnr, tpr_train, tpr_test = evaluation.unsupervised_evaluation(OCSVM, x_train, x_test, x_attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TNR: {}\\nTPR_test: {}\\nTPR_train: {}\\n'.format(tnr, tpr_test, tpr_train))\n",
    "print('F20: {}\\nAUC: {}'.format(fb, area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = OCSVM.decision_function(x_train)\n",
    "test_scores = OCSVM.decision_function(x_test)\n",
    "attack_scores = OCSVM.decision_function(x_attacks)\n",
    "\n",
    "print('Mean score values:\\n-Train: {}\\n-Test: {}\\n-Attacks: {}'.format(np.mean(train_scores),\n",
    "                                                                       np.mean(test_scores),\n",
    "                                                                       np.mean(attack_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Box(\n",
    "    y=test_scores,\n",
    "    name='test'\n",
    "    \n",
    ")\n",
    "trace1 = go.Box(\n",
    "    y=attack_scores,\n",
    "    name='attacks'\n",
    ")\n",
    "data = [trace0, trace1]\n",
    "\n",
    "layout = {'title': 'Boxplots', \n",
    "          'yaxis': {'title': 'Distance to decision function'}\n",
    "         }\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative distances mean points outside the decision function thus, classified as attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will study the distances to the decision function comparing them to different attacks and resolutions, in order to gain insights of the model we have built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_attacks = df_train.reset_index(), df_test.reset_index(), df_attacks.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['distance_to_dec_func'] = train_scores\n",
    "df_test['distance_to_dec_func'] = test_scores\n",
    "df_attacks['distance_to_dec_func'] = attack_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = df_test['dimension'].unique()\n",
    "attacks = df_attacks['attack'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "resolutions = np.sort(resolutions)\n",
    "for res in resolutions:\n",
    "    selection = df_test[df_test['dimension'] == res]\n",
    "    trace = go.Box(y = selection['distance_to_dec_func'], name = str(res) + 'p',\n",
    "                   text = selection['title']\n",
    ")\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "            title=go.layout.Title(text='Test Set'),\n",
    "            yaxis = go.layout.YAxis(title = 'Distance to decision function'),\n",
    "            xaxis = go.layout.XAxis(\n",
    "                title = 'Resolutions',\n",
    "                tickmode = 'array',\n",
    "                ticktext = [str(i) + 'p' for i in resolutions]\n",
    "            )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "resolutions = np.sort(resolutions)\n",
    "for res in resolutions:\n",
    "    selection = df_attacks[df_attacks['dimension'] == res]\n",
    "    trace = go.Box(y = selection['distance_to_dec_func'], name = str(res) + 'p',\n",
    "                   text = selection['title']\n",
    ")\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "            title=go.layout.Title(text='Attack Set'),\n",
    "            yaxis = go.layout.YAxis(title = 'Distance to decision function'),\n",
    "            xaxis = go.layout.XAxis(\n",
    "                title = 'Resolutions',\n",
    "                tickmode = 'array',\n",
    "                ticktext = [str(i) + 'p' for i in resolutions]\n",
    "            )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "attack_types = list(set([i.split('_', 1)[1] for i in attacks]))\n",
    "for attk in attack_types:\n",
    "    selection = df_attacks[df_attacks['attack'].str.contains(attk)]\n",
    "    trace = go.Box(y = selection['distance_to_dec_func'], name = attk, text = selection['title'])\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(\n",
    "            title=go.layout.Title(text='Attack Set'),\n",
    "            yaxis = go.layout.YAxis(title = 'Distance to decision function'),\n",
    "            xaxis = go.layout.XAxis(\n",
    "                title = 'Attack Type',\n",
    "                tickmode = 'array',\n",
    "                ticktext = attack_types\n",
    "            )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for res in resolutions:\n",
    "    for attk in attack_types:\n",
    "        selection = df_attacks[(df_attacks['attack'].str.contains(attk)) & (df_attacks['dimension'] == res)]\n",
    "        trace = go.Box(y = selection['distance_to_dec_func'], name = '{}p-{}'.format(res,attk),\n",
    "        text = selection['title'])\n",
    "        data.append(trace)\n",
    "\n",
    "\n",
    "\n",
    "    layout = go.Layout(\n",
    "            title=go.layout.Title(text=str(res)+ 'p'),\n",
    "            yaxis = go.layout.YAxis(title = 'Distance to decision function'),\n",
    "            xaxis = go.layout.XAxis(\n",
    "                title = 'Attack Type',\n",
    "                tickmode = 'array',\n",
    "                ticktext = attack_types\n",
    "            )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    offline.iplot(fig)\n",
    "    data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
